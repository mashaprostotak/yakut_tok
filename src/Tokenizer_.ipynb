{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (2.2.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (2.3.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merging tokenizer training texts into a single file per language. \n",
        "\n",
        "import os\n",
        "\n",
        "os.makedirs('output', exist_ok=True)\n",
        "\n",
        "# Open output file in write mode\n",
        "with open('output/merged_texts.txt', 'w', encoding='utf-8') as outfile:\n",
        "    # Walk through the texts directory\n",
        "    for root, dirs, files in os.walk('/Users/abu/Downloads/CustomLlamaTok/Yakut_train'):\n",
        "        for file in files:\n",
        "            if file.endswith('.txt'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                # Read each text file and write to merged file\n",
        "                with open(file_path, 'r', encoding='utf-8') as infile:\n",
        "                    outfile.write(infile.read())\n",
        "                    outfile.write('\\n\\n')  # Add spacing between files\n",
        "\n",
        "print(\"All text files have been merged into output/merged_texts.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training multilingual tokenizer...\n",
            "\n",
            "\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing tokenization:\n",
            "\n",
            "Input: <|begin_of_text|><sah>Мин аатым Кэскил.\n",
            "Tokens: ['<|begin_of_text|>', '<sah>', 'ĠÐľÐ¸Ð', '½', 'ĠÐ°Ð°ÑĤÑĭÐ', '¼', 'ĠÐļÑįÑģÐºÐ¸Ð', '»', '.']\n",
            "Decoded: ['<|begin_of_text|>', '<sah>', ' Ми�', '�', ' ааты�', '�', ' Кэски�', '�', '.']\n",
            "\n",
            "Input: <|begin_of_text|><ru>Привет, как дела?\n",
            "Tokens: ['<|begin_of_text|>', '<ru>', 'ĠÐŁÑĢÐ¸Ð', '²', 'ÐµÑĤ', ',', 'ĠÐºÐ°Ðº', 'ĠÐ´ÐµÐ', '»', 'Ð°', '?']\n",
            "Decoded: ['<|begin_of_text|>', '<ru>', ' При�', '�', 'ет', ',', ' как', ' де�', '�', 'а', '?']\n",
            "\n",
            "Input: <|begin_of_text|><en>To fix this issue\n",
            "Tokens: ['<|begin_of_text|>', '<en>', 'ĠTo', 'Ġfix', 'Ġthis', 'Ġissue']\n",
            "Decoded: ['<|begin_of_text|>', '<en>', ' To', ' fix', ' this', ' issue']\n",
            "\n",
            "Tokenizer saved to: multilingual-tokenizer\n"
          ]
        }
      ],
      "source": [
        "'''from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "import os\n",
        "\n",
        "# 1. Gather multilingual corpus\n",
        "corpus_files = [\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/Yakut_Train/SH_merged_texts.txt',         # Yakut\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/Russian_Train/RU_merged_texts.txt',                  # Russian\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/English_Train/EN_merged_texts.txt'                   # English\n",
        "]\n",
        "\n",
        "# 2. Create tokenizer with BPE model\n",
        "tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
        "\n",
        "# 3. Multilingual pre-tokenization\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.Sequence([\n",
        "    pre_tokenizers.ByteLevel(add_prefix_space=True),\n",
        "    pre_tokenizers.Punctuation(),\n",
        "    pre_tokenizers.Digits(individual_digits=False)\n",
        "])\n",
        "\n",
        "# 4. Special tokens\n",
        "special_tokens = [\n",
        "    \"<|begin_of_text|>\", \n",
        "    \"<|end_of_text|>\", \n",
        "    \"<unk>\", \n",
        "    \"<pad>\",\n",
        "    \"<en>\",  # English language token\n",
        "    \"<ru>\",  # Russian language token\n",
        "    \"<sah>\"  # Yakut language token\n",
        "]\n",
        "\n",
        "# 5. Trainer configuration for multilingual\n",
        "trainer = trainers.BpeTrainer(\n",
        "    vocab_size=50000,  # Larger vocabulary for multiple languages\n",
        "    special_tokens=special_tokens,\n",
        "    min_frequency=2,\n",
        "    show_progress=True,\n",
        "    limit_alphabet=2000,  # Larger alphabet for Cyrillic + Latin\n",
        "    initial_alphabet=pre_tokenizers.ByteLevel.alphabet()\n",
        ")\n",
        "\n",
        "# 6. Train on multilingual data\n",
        "print(\"Training multilingual tokenizer...\")\n",
        "tokenizer.train(files=corpus_files, trainer=trainer)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# 7. Configure processing\n",
        "tokenizer.decoder = decoders.ByteLevel()\n",
        "\n",
        "# 8. Save tokenizer\n",
        "tokenizer.save(\"multilingual_tokenizer.json\")\n",
        "\n",
        "# 9. Load as HF tokenizer\n",
        "hf_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=\"multilingual_tokenizer.json\",\n",
        "    bos_token=\"<|begin_of_text|>\",\n",
        "    eos_token=\"<|end_of_text|>\",\n",
        "    unk_token=\"<unk>\",\n",
        "    pad_token=\"<pad>\",\n",
        "    additional_special_tokens=[\"<en>\", \"<ru>\", \"<sah>\"]\n",
        ")\n",
        "\n",
        "# 10. Test all languages\n",
        "def print_tokenization(text):\n",
        "    tokens = hf_tokenizer.tokenize(text)\n",
        "    decoded = [hf_tokenizer.convert_tokens_to_string([t]) for t in tokens]\n",
        "    print(f\"\\nInput: {text}\")\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "    print(f\"Decoded: {decoded}\")\n",
        "\n",
        "print(\"\\nTesting tokenization:\")\n",
        "print_tokenization(\"<|begin_of_text|><sah>Мин аатым Кэскил.\")  # Yakut\n",
        "print_tokenization(\"<|begin_of_text|><ru>Привет, как дела?\")   # Russian\n",
        "print_tokenization(\"<|begin_of_text|><en>To fix this issue\")    # English\n",
        "\n",
        "# 11. Save tokenizer\n",
        "save_path = \"multilingual-tokenizer\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "hf_tokenizer.save_pretrained(save_path)\n",
        "print(f\"\\nTokenizer saved to: {save_path}\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training improved multilingual tokenizer...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Trail 1; Multilingual Tokenizer; Suboptimal tokenization. \n",
        "\n",
        "\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "import os\n",
        "\n",
        "# 1. Gather multilingual corpus\n",
        "corpus_files = [\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/Yakut_Train/SH_merged_texts.txt',  # Yakut\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/Russian_Train/RU_merged_texts.txt',  # Russian\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/English_Train/EN_merged_texts.txt'   # English\n",
        "]\n",
        "\n",
        "# 2. Create tokenizer with BPE model\n",
        "tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
        "\n",
        "# 3. Improved multilingual pre-tokenization\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.Sequence([\n",
        "    pre_tokenizers.UnicodeScripts(),  # Better for multilingual\n",
        "    pre_tokenizers.Punctuation(),\n",
        "    pre_tokenizers.Digits(individual_digits=False)\n",
        "])\n",
        "\n",
        "# 4. Special tokens\n",
        "special_tokens = [\n",
        "    \"<|begin_of_text|>\", \n",
        "    \"<|end_of_text|>\", \n",
        "    \"<unk>\", \n",
        "    \"<pad>\",\n",
        "    \"<en>\",  # English language token\n",
        "    \"<ru>\",  # Russian language token\n",
        "    \"<sah>\"  # Yakut language token\n",
        "]\n",
        "\n",
        "# 5. Enhanced trainer configuration\n",
        "trainer = trainers.BpeTrainer(\n",
        "    vocab_size=50000,\n",
        "    special_tokens=special_tokens,\n",
        "    min_frequency=3,  # Increased frequency for better subwords\n",
        "    show_progress=True,\n",
        "    limit_alphabet=5000,  # Increased for Cyrillic + Latin\n",
        "    initial_alphabet=pre_tokenizers.ByteLevel.alphabet(),\n",
        "    continuing_subword_prefix=\"▁\",  # Add prefix for better word boundaries\n",
        ")\n",
        "\n",
        "# 6. Train on multilingual data\n",
        "print(\"Training improved multilingual tokenizer...\")\n",
        "tokenizer.train(files=corpus_files, trainer=trainer)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# 7. Configure processing\n",
        "tokenizer.decoder = decoders.Sequence([\n",
        "    decoders.Replace(\"▁\", \" \"),  # Convert back to spaces\n",
        "    decoders.ByteLevel()\n",
        "])\n",
        "\n",
        "# 8. Save tokenizer\n",
        "tokenizer.save(\"yakut_tokenizer.json\")\n",
        "\n",
        "# 9. Load as HF tokenizer\n",
        "hf_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=\"yakut_tokenizer.json\",\n",
        "    bos_token=\"<|begin_of_text|>\",\n",
        "    eos_token=\"<|end_of_text|>\",\n",
        "    unk_token=\"<unk>\",\n",
        "    pad_token=\"<pad>\",\n",
        "    additional_special_tokens=[\"<en>\", \"<ru>\", \"<sah>\"]\n",
        ")\n",
        "\n",
        "# 10. Test all languages\n",
        "def print_tokenization(text):\n",
        "    tokens = hf_tokenizer.tokenize(text)\n",
        "    decoded = hf_tokenizer.convert_tokens_to_string(tokens)\n",
        "    print(f\"\\nInput: {text}\")\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "    print(f\"Decoded: {decoded}\")\n",
        "\n",
        "print(\"\\nTesting tokenization:\")\n",
        "print_tokenization(\"<|begin_of_text|><sah>Мин аатым Кэскил.\")  # Yakut\n",
        "print_tokenization(\"<|begin_of_text|><ru>Привет, как дела?\")   # Russian\n",
        "print_tokenization(\"<|begin_of_text|><en>To fix this issue\")    # English\n",
        "\n",
        "# 11. Save tokenizer\n",
        "save_path = \"yakut_tokenizer\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "hf_tokenizer.save_pretrained(save_path)\n",
        "print(f\"\\nTokenizer saved to: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "yakut-tokenizer is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/yakut-tokenizer/resolve/main/tokenizer_config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/transformers/utils/hub.py:470\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:1008\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:1115\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1115\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:1645\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1641\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[1;32m   1642\u001b[0m ):\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:1533\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1533\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:1450\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1450\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m hf_raise_for_status(r)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:286\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 286\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:310\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    309\u001b[0m response \u001b[38;5;241m=\u001b[39m http_backoff(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, retry_on_exceptions\u001b[38;5;241m=\u001b[39m(), retry_on_status_codes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m429\u001b[39m,))\n\u001b[0;32m--> 310\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:459\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    450\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    458\u001b[0m     )\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-684cfe86-4d84e3a82c417f7d12d2ffcf;3fc679c7-a4ff-46e6-9dce-370f45f49f4f)\n\nRepository Not Found for url: https://huggingface.co/yakut-tokenizer/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 1. Load your Yakut tokenizer\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m yakut_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myakut-tokenizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 2. Load Llama 3 model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3-1B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_iwTFtLrOyizDmnYjwmlGCLwGMhOADKtroP\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:950\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 950\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    952\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:782\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    779\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    781\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 782\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    799\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/transformers/utils/hub.py:312\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_file\u001b[39m(\n\u001b[1;32m    255\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    256\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/transformers/utils/hub.py:502\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n\u001b[0;32m--> 502\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    506\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    507\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RevisionNotFoundError):\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    512\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mOSError\u001b[0m: yakut-tokenizer is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# 1. Load your Yakut tokenizer\n",
        "yakut_tokenizer = AutoTokenizer.from_pretrained(\"yakut-tokenizer\")\n",
        "\n",
        "# 2. Load Llama 3 model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-3-1B\",\n",
        "    token=\"hf_iwTFtLrOyizDmnYjwmlGCLwGMhOADK\"\n",
        ")\n",
        "\n",
        "# 3. Resize embeddings\n",
        "original_vocab_size = model.get_input_embeddings().weight.size(0)\n",
        "new_vocab_size = len(yakut_tokenizer)\n",
        "model.resize_token_embeddings(new_vocab_size)\n",
        "\n",
        "# 4. Initialize new embeddings\n",
        "print(f\"\\nInitializing new embeddings...\")\n",
        "with torch.no_grad():\n",
        "    # Copy embeddings for tokens that exist in both vocabularies\n",
        "    for token, idx in yakut_tokenizer.get_vocab().items():\n",
        "        if idx < original_vocab_size:\n",
        "            # Only initialize new tokens\n",
        "            continue\n",
        "        # Initialize with mean of existing embeddings\n",
        "        model.get_input_embeddings().weight[idx] = model.get_input_embeddings().weight.mean(dim=0)\n",
        "    \n",
        "    # Tie weights if needed\n",
        "    if model.config.tie_word_embeddings:\n",
        "        model.lm_head.weight = model.get_input_embeddings().weight\n",
        "\n",
        "# 5. Save the custom model\n",
        "model.save_pretrained(\"yakut-llama-model\")\n",
        "yakut_tokenizer.save_pretrained(\"yakut-llama-model\")\n",
        "print(\"Custom model saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (2.2.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (2.3.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/DL/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merging tokenizer training texts into a single file per language. \n",
        "\n",
        "import os\n",
        "\n",
        "os.makedirs('output', exist_ok=True)\n",
        "\n",
        "# Open output file in write mode\n",
        "with open('output/merged_texts.txt', 'w', encoding='utf-8') as outfile:\n",
        "    # Walk through the texts directory\n",
        "    for root, dirs, files in os.walk('/Users/abu/Downloads/CustomLlamaTok/Yakut_train'):\n",
        "        for file in files:\n",
        "            if file.endswith('.txt'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                # Read each text file and write to merged file\n",
        "                with open(file_path, 'r', encoding='utf-8') as infile:\n",
        "                    outfile.write(infile.read())\n",
        "                    outfile.write('\\n\\n')  # Add spacing between files\n",
        "\n",
        "print(\"All text files have been merged into output/merged_texts.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training multilingual tokenizer...\n",
            "\n",
            "\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing tokenization:\n",
            "\n",
            "Input: <|begin_of_text|><sah>Мин аатым Кэскил.\n",
            "Tokens: ['<|begin_of_text|>', '<sah>', 'ĠÐľÐ¸Ð', '½', 'ĠÐ°Ð°ÑĤÑĭÐ', '¼', 'ĠÐļÑįÑģÐºÐ¸Ð', '»', '.']\n",
            "Decoded: ['<|begin_of_text|>', '<sah>', ' Ми�', '�', ' ааты�', '�', ' Кэски�', '�', '.']\n",
            "\n",
            "Input: <|begin_of_text|><ru>Привет, как дела?\n",
            "Tokens: ['<|begin_of_text|>', '<ru>', 'ĠÐŁÑĢÐ¸Ð', '²', 'ÐµÑĤ', ',', 'ĠÐºÐ°Ðº', 'ĠÐ´ÐµÐ', '»', 'Ð°', '?']\n",
            "Decoded: ['<|begin_of_text|>', '<ru>', ' При�', '�', 'ет', ',', ' как', ' де�', '�', 'а', '?']\n",
            "\n",
            "Input: <|begin_of_text|><en>To fix this issue\n",
            "Tokens: ['<|begin_of_text|>', '<en>', 'ĠTo', 'Ġfix', 'Ġthis', 'Ġissue']\n",
            "Decoded: ['<|begin_of_text|>', '<en>', ' To', ' fix', ' this', ' issue']\n",
            "\n",
            "Tokenizer saved to: multilingual-tokenizer\n"
          ]
        }
      ],
      "source": [
        "'''from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "import os\n",
        "\n",
        "# 1. Gather multilingual corpus\n",
        "corpus_files = [\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/Yakut_Train/SH_merged_texts.txt',         # Yakut\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/Russian_Train/RU_merged_texts.txt',                  # Russian\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/English_Train/EN_merged_texts.txt'                   # English\n",
        "]\n",
        "\n",
        "# 2. Create tokenizer with BPE model\n",
        "tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
        "\n",
        "# 3. Multilingual pre-tokenization\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.Sequence([\n",
        "    pre_tokenizers.ByteLevel(add_prefix_space=True),\n",
        "    pre_tokenizers.Punctuation(),\n",
        "    pre_tokenizers.Digits(individual_digits=False)\n",
        "])\n",
        "\n",
        "# 4. Special tokens\n",
        "special_tokens = [\n",
        "    \"<|begin_of_text|>\", \n",
        "    \"<|end_of_text|>\", \n",
        "    \"<unk>\", \n",
        "    \"<pad>\",\n",
        "    \"<en>\",  # English language token\n",
        "    \"<ru>\",  # Russian language token\n",
        "    \"<sah>\"  # Yakut language token\n",
        "]\n",
        "\n",
        "# 5. Trainer configuration for multilingual\n",
        "trainer = trainers.BpeTrainer(\n",
        "    vocab_size=50000,  # Larger vocabulary for multiple languages\n",
        "    special_tokens=special_tokens,\n",
        "    min_frequency=2,\n",
        "    show_progress=True,\n",
        "    limit_alphabet=2000,  # Larger alphabet for Cyrillic + Latin\n",
        "    initial_alphabet=pre_tokenizers.ByteLevel.alphabet()\n",
        ")\n",
        "\n",
        "# 6. Train on multilingual data\n",
        "print(\"Training multilingual tokenizer...\")\n",
        "tokenizer.train(files=corpus_files, trainer=trainer)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# 7. Configure processing\n",
        "tokenizer.decoder = decoders.ByteLevel()\n",
        "\n",
        "# 8. Save tokenizer\n",
        "tokenizer.save(\"multilingual_tokenizer.json\")\n",
        "\n",
        "# 9. Load as HF tokenizer\n",
        "hf_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=\"multilingual_tokenizer.json\",\n",
        "    bos_token=\"<|begin_of_text|>\",\n",
        "    eos_token=\"<|end_of_text|>\",\n",
        "    unk_token=\"<unk>\",\n",
        "    pad_token=\"<pad>\",\n",
        "    additional_special_tokens=[\"<en>\", \"<ru>\", \"<sah>\"]\n",
        ")\n",
        "\n",
        "# 10. Test all languages\n",
        "def print_tokenization(text):\n",
        "    tokens = hf_tokenizer.tokenize(text)\n",
        "    decoded = [hf_tokenizer.convert_tokens_to_string([t]) for t in tokens]\n",
        "    print(f\"\\nInput: {text}\")\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "    print(f\"Decoded: {decoded}\")\n",
        "\n",
        "print(\"\\nTesting tokenization:\")\n",
        "print_tokenization(\"<|begin_of_text|><sah>Мин аатым Кэскил.\")  # Yakut\n",
        "print_tokenization(\"<|begin_of_text|><ru>Привет, как дела?\")   # Russian\n",
        "print_tokenization(\"<|begin_of_text|><en>To fix this issue\")    # English\n",
        "\n",
        "# 11. Save tokenizer\n",
        "save_path = \"multilingual-tokenizer\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "hf_tokenizer.save_pretrained(save_path)\n",
        "print(f\"\\nTokenizer saved to: {save_path}\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training improved multilingual tokenizer...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Trail 1; Multilingual Tokenizer; Suboptimal tokenization. \n",
        "\n",
        "\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "import os\n",
        "\n",
        "# 1. Gather multilingual corpus\n",
        "corpus_files = [\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/Yakut_Train/SH_merged_texts.txt',  # Yakut\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/Russian_Train/RU_merged_texts.txt',  # Russian\n",
        "    '/Users/abu/Downloads/CustomLlamaTok/English_Train/EN_merged_texts.txt'   # English\n",
        "]\n",
        "\n",
        "# 2. Create tokenizer with BPE model\n",
        "tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
        "\n",
        "# 3. Improved multilingual pre-tokenization\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.Sequence([\n",
        "    pre_tokenizers.UnicodeScripts(),  # Better for multilingual\n",
        "    pre_tokenizers.Punctuation(),\n",
        "    pre_tokenizers.Digits(individual_digits=False)\n",
        "])\n",
        "\n",
        "# 4. Special tokens\n",
        "special_tokens = [\n",
        "    \"<|begin_of_text|>\", \n",
        "    \"<|end_of_text|>\", \n",
        "    \"<unk>\", \n",
        "    \"<pad>\",\n",
        "    \"<en>\",  # English language token\n",
        "    \"<ru>\",  # Russian language token\n",
        "    \"<sah>\"  # Yakut language token\n",
        "]\n",
        "\n",
        "# 5. Enhanced trainer configuration\n",
        "trainer = trainers.BpeTrainer(\n",
        "    vocab_size=50000,\n",
        "    special_tokens=special_tokens,\n",
        "    min_frequency=3,  # Increased frequency for better subwords\n",
        "    show_progress=True,\n",
        "    limit_alphabet=5000,  # Increased for Cyrillic + Latin\n",
        "    initial_alphabet=pre_tokenizers.ByteLevel.alphabet(),\n",
        "    continuing_subword_prefix=\"▁\",  # Add prefix for better word boundaries\n",
        ")\n",
        "\n",
        "# 6. Train on multilingual data\n",
        "print(\"Training improved multilingual tokenizer...\")\n",
        "tokenizer.train(files=corpus_files, trainer=trainer)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# 7. Configure processing\n",
        "tokenizer.decoder = decoders.Sequence([\n",
        "    decoders.Replace(\"▁\", \" \"),  # Convert back to spaces\n",
        "    decoders.ByteLevel()\n",
        "])\n",
        "\n",
        "# 8. Save tokenizer\n",
        "tokenizer.save(\"yakut_tokenizer.json\")\n",
        "\n",
        "# 9. Load as HF tokenizer\n",
        "hf_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=\"yakut_tokenizer.json\",\n",
        "    bos_token=\"<|begin_of_text|>\",\n",
        "    eos_token=\"<|end_of_text|>\",\n",
        "    unk_token=\"<unk>\",\n",
        "    pad_token=\"<pad>\",\n",
        "    additional_special_tokens=[\"<en>\", \"<ru>\", \"<sah>\"]\n",
        ")\n",
        "\n",
        "# 10. Test all languages\n",
        "def print_tokenization(text):\n",
        "    tokens = hf_tokenizer.tokenize(text)\n",
        "    decoded = hf_tokenizer.convert_tokens_to_string(tokens)\n",
        "    print(f\"\\nInput: {text}\")\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "    print(f\"Decoded: {decoded}\")\n",
        "\n",
        "print(\"\\nTesting tokenization:\")\n",
        "print_tokenization(\"<|begin_of_text|><sah>Мин аатым Кэскил.\")  # Yakut\n",
        "print_tokenization(\"<|begin_of_text|><ru>Привет, как дела?\")   # Russian\n",
        "print_tokenization(\"<|begin_of_text|><en>To fix this issue\")    # English\n",
        "\n",
        "# 11. Save tokenizer\n",
        "save_path = \"yakut_tokenizer\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "hf_tokenizer.save_pretrained(save_path)\n",
        "print(f\"\\nTokenizer saved to: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "yakut-tokenizer is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n",
            "\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n",
            "\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
            "\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/yakut-tokenizer/resolve/main/tokenizer_config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/transformers/utils/hub.py:470\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n",
            "\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n",
            "\u001b[0;32m--> 470\u001b[0m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
            "\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:1008\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n",
            "\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n",
            "\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n",
            "\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n",
            "\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n",
            "\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:1115\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n",
            "\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n",
            "\u001b[0;32m-> 1115\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m   1117\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:1645\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n",
            "\u001b[1;32m   1640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n",
            "\u001b[1;32m   1641\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n",
            "\u001b[1;32m   1642\u001b[0m ):\n",
            "\u001b[1;32m   1643\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n",
            "\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n",
            "\u001b[0;32m-> 1645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n",
            "\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;32m   1647\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:1533\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n",
            "\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[0;32m-> 1533\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n",
            "\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
            "\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:1450\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n",
            "\u001b[1;32m   1449\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n",
            "\u001b[0;32m-> 1450\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[1;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m   1458\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m   1459\u001b[0m hf_raise_for_status(r)\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:286\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n",
            "\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n",
            "\u001b[0;32m--> 286\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n",
            "\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/file_download.py:310\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n",
            "\u001b[1;32m    309\u001b[0m response \u001b[38;5;241m=\u001b[39m http_backoff(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, retry_on_exceptions\u001b[38;5;241m=\u001b[39m(), retry_on_status_codes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m429\u001b[39m,))\n",
            "\u001b[0;32m--> 310\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:459\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n",
            "\u001b[1;32m    450\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n",
            "\u001b[1;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m    452\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m    458\u001b[0m     )\n",
            "\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
            "\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-684cfe86-4d84e3a82c417f7d12d2ffcf;3fc679c7-a4ff-46e6-9dce-370f45f49f4f)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/yakut-tokenizer/resolve/main/tokenizer_config.json.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\n",
            "Invalid username or password.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n",
            "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
            "\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 1. Load your Yakut tokenizer\u001b[39;00m\n",
            "\u001b[0;32m----> 5\u001b[0m yakut_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myakut-tokenizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 2. Load Llama 3 model\u001b[39;00m\n",
            "\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n",
            "\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3-1B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
            "\u001b[1;32m     10\u001b[0m     token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_iwTFtLrOyizDmnYjwmlGCLwGMhOADKtroP\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m     11\u001b[0m )\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:950\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n",
            "\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n",
            "\u001b[0;32m--> 950\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n",
            "\u001b[1;32m    952\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:782\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n",
            "\u001b[1;32m    779\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n",
            "\u001b[1;32m    781\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[0;32m--> 782\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[1;32m    797\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;32m    799\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/transformers/utils/hub.py:312\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n",
            "\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_file\u001b[39m(\n",
            "\u001b[1;32m    255\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n",
            "\u001b[1;32m    256\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n",
            "\u001b[1;32m    257\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n",
            "\u001b[1;32m    258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n",
            "\u001b[1;32m    259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
            "\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n",
            "\u001b[1;32m    261\u001b[0m \n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n",
            "\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[0;32m--> 312\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    313\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n",
            "\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
            "\n",
            "File \u001b[0;32m/opt/anaconda3/envs/DL/lib/python3.10/site-packages/transformers/utils/hub.py:502\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n",
            "\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n",
            "\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n",
            "\u001b[0;32m--> 502\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n",
            "\u001b[1;32m    503\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m    504\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m    505\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m    506\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m    507\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RevisionNotFoundError):\n",
            "\u001b[1;32m    509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n",
            "\u001b[1;32m    510\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m    511\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m    512\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m    513\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
            "\n",
            "\u001b[0;31mOSError\u001b[0m: yakut-tokenizer is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# 1. Load your Yakut tokenizer\n",
        "yakut_tokenizer = AutoTokenizer.from_pretrained(\"yakut-tokenizer\")\n",
        "\n",
        "# 2. Load Llama 3 model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-3-1B\",\n",
        "    token=\"hf_iwTFtLrOyizDmnYjwmlGCLwGMhOADK\"\n",
        ")\n",
        "\n",
        "# 3. Resize embeddings\n",
        "original_vocab_size = model.get_input_embeddings().weight.size(0)\n",
        "new_vocab_size = len(yakut_tokenizer)\n",
        "model.resize_token_embeddings(new_vocab_size)\n",
        "\n",
        "# 4. Initialize new embeddings\n",
        "print(f\"\\nInitializing new embeddings...\")\n",
        "with torch.no_grad():\n",
        "    # Copy embeddings for tokens that exist in both vocabularies\n",
        "    for token, idx in yakut_tokenizer.get_vocab().items():\n",
        "        if idx < original_vocab_size:\n",
        "            # Only initialize new tokens\n",
        "            continue\n",
        "        # Initialize with mean of existing embeddings\n",
        "        model.get_input_embeddings().weight[idx] = model.get_input_embeddings().weight.mean(dim=0)\n",
        "    \n",
        "    # Tie weights if needed\n",
        "    if model.config.tie_word_embeddings:\n",
        "        model.lm_head.weight = model.get_input_embeddings().weight\n",
        "\n",
        "# 5. Save the custom model\n",
        "model.save_pretrained(\"yakut-llama-model\")\n",
        "yakut_tokenizer.save_pretrained(\"yakut-llama-model\")\n",
        "print(\"Custom model saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Login to Hugging Face\n",
        "login(token=\"hf_iwTFtLrOyizDmnYjwmlGCLwGMhOADK\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2b3e9718a014690b2c7287d9430cf2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "447b75b6ae534adcb0884c042e16b4ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c3f78cd69444b92a54564cbb48329c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original vocab size: 128256\n",
            "New vocab size: 50000\n",
            "\n",
            "Creating new embeddings...\n",
            "\n",
            "Custom model saved to: yakut-llama-model\n",
            "\n",
            "Test inference:\n",
            "Logits shape: torch.Size([1, 6, 50000])\n",
            "Generated text: <|begin_of_text|>Мин  аатым  К эскил.Indo,Indo,Indo,Indo,Indo,Indo,Indo\n"
          ]
        }
      ],
      "source": [
        "#Trail 2: Multilingual Tokenizer; decent tokenization. \n",
        "\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# 1. Load your Yakut tokenizer\n",
        "tokenizer_path = \"/Users/abu/Downloads/CustomLlamaTok/yakut_tokenizer\"\n",
        "yakut_tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "# 2. Load Llama 3 model and tokenizer\n",
        "model_name = \"meta-llama/Llama-3.2-1B\"\n",
        "token = \"hf_ynsefXAVByqhClmLjMARNwGQJkBikq\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    token=token\n",
        ")\n",
        "\n",
        "# Load the ORIGINAL tokenizer for Llama\n",
        "original_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    token=token\n",
        ")\n",
        "\n",
        "# 3. Get vocabulary sizes\n",
        "original_vocab_size = model.config.vocab_size\n",
        "new_vocab_size = len(yakut_tokenizer)\n",
        "print(f\"Original vocab size: {original_vocab_size}\")\n",
        "print(f\"New vocab size: {new_vocab_size}\")\n",
        "\n",
        "# 4. Create new embedding matrix\n",
        "print(\"\\nCreating new embeddings...\")\n",
        "with torch.no_grad():\n",
        "    # Get original embeddings\n",
        "    original_embeddings = model.get_input_embeddings().weight.data.clone()\n",
        "    mean_embedding = original_embeddings.mean(dim=0)\n",
        "    \n",
        "    # Create new embedding layer\n",
        "    new_embeddings = torch.nn.Embedding(new_vocab_size, model.config.hidden_size)\n",
        "    \n",
        "    # Get vocabulary of the original tokenizer\n",
        "    original_vocab = original_tokenizer.get_vocab()\n",
        "    \n",
        "    # Copy embeddings for overlapping tokens\n",
        "    for token, new_idx in yakut_tokenizer.get_vocab().items():\n",
        "        # Check if token exists in original tokenizer\n",
        "        if token in original_vocab:\n",
        "            old_idx = original_vocab[token]\n",
        "            new_embeddings.weight[new_idx] = original_embeddings[old_idx].clone()\n",
        "        else:\n",
        "            # For new tokens, use mean embedding\n",
        "            new_embeddings.weight[new_idx] = mean_embedding\n",
        "    \n",
        "    # Replace model embeddings\n",
        "    model.set_input_embeddings(new_embeddings)\n",
        "    \n",
        "    # Update config\n",
        "    model.config.vocab_size = new_vocab_size\n",
        "    \n",
        "    # Tie weights if needed\n",
        "    if model.config.tie_word_embeddings:\n",
        "        model.lm_head.weight = model.get_input_embeddings().weight\n",
        "\n",
        "# 5. Save the custom model\n",
        "save_path = \"yakut-llama-model\"\n",
        "model.save_pretrained(save_path)\n",
        "yakut_tokenizer.save_pretrained(save_path)\n",
        "print(f\"\\nCustom model saved to: {save_path}\")\n",
        "\n",
        "# 6. Test the model with proper settings\n",
        "test_text = \"<|begin_of_text|>Мин аатым Кэскил.\"\n",
        "inputs = yakut_tokenizer(test_text, return_tensors=\"pt\")\n",
        "\n",
        "# Set pad token if not set\n",
        "if yakut_tokenizer.pad_token is None:\n",
        "    yakut_tokenizer.pad_token = yakut_tokenizer.eos_token\n",
        "    model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "print(\"\\nTest inference:\")\n",
        "with torch.no_grad():\n",
        "    # Forward pass\n",
        "    outputs = model(**inputs)\n",
        "    print(f\"Logits shape: {outputs.logits.shape}\")\n",
        "    \n",
        "    # Test generation with attention mask\n",
        "    generated = model.generate(\n",
        "        inputs.input_ids,\n",
        "        attention_mask=inputs.attention_mask,\n",
        "        max_new_tokens=20,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=yakut_tokenizer.pad_token_id\n",
        "    )\n",
        "    decoded = yakut_tokenizer.decode(generated[0], skip_special_tokens=False)\n",
        "    print(f\"Generated text: {decoded}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**RUSSIAN**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32e48ed387c34465bc814dc9f82d2da4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenization test:\n",
            "Input text: <|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\n",
            "Token IDs: [0, 2696, 1031, 17, 3091, 4415, 8687, 18, 1138, 20195, 1162, 4415, 8687, 16, 20548, 1162, 4498, 6162, 18406, 3685, 17454, 4297, 4450, 382, 1197, 10381, 1058, 1401, 1009, 1121, 20132, 1388, 25376, 18]\n",
            "Tokens: ['<|begin_of_text|>', '▁Ж', 'ил', '-', 'был', '▁ц', 'арь', '.', '▁Д', 'обр', 'ый', '▁ц', 'арь', ',', '▁котор', 'ый', '▁оч', 'ень', '▁лю', 'бил', '▁сво', 'их', '▁под', 'д', 'анн', 'ых', '▁и', '▁был', '▁с', '▁н', 'ими', '▁л', 'асков', '.']\n",
            "\n",
            "Forward pass test:\n",
            "Logits shape: torch.Size([1, 34, 30000])\n",
            "Forward pass successful!\n",
            "\n",
            "Embedding test:\n",
            "Embedding shape: torch.Size([1, 34, 4096])\n",
            "Embedding norms: 0.5088\n"
          ]
        }
      ],
      "source": [
        "# Tokenization Trail using trail 1 Multilingual Tokenizer; Suboptimal tokenization.     \n",
        "\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "\n",
        "# Load your custom model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\"yakut-llama-model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"yakut-llama-model\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Test tokenization\n",
        "text = \"<|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "print(\"Tokenization test:\")\n",
        "print(f\"Input text: {text}\")\n",
        "print(f\"Token IDs: {inputs['input_ids'].tolist()[0]}\")\n",
        "print(f\"Tokens: {tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])}\")\n",
        "\n",
        "# Test forward pass\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "print(\"\\nForward pass test:\")\n",
        "print(f\"Logits shape: {outputs.logits.shape}\")  # Should be [1, seq_len, vocab_size]\n",
        "print(\"Forward pass successful!\")\n",
        "\n",
        "# Test embedding layer\n",
        "input_embeds = model.get_input_embeddings()(inputs.input_ids)\n",
        "print(f\"\\nEmbedding test:\")\n",
        "print(f\"Embedding shape: {input_embeds.shape}\")  # Should be [1, seq_len, hidden_size]\n",
        "print(f\"Embedding norms: {torch.norm(input_embeds, dim=2).mean().item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "Testing Yakut text\n",
            "========================================\n",
            "\n",
            "Tokenization:\n",
            "Input text: <|begin_of_text|>Араас сылларга үөрэнэн ааспыт училещаларын үбүлүөйүн көрсө кэллилэр ыраахтан-чугастан элбэх ыалдьыт\n",
            "Token IDs: [0, 7931, 5567, 16944, 16780, 17172, 5546, 4560, 49601, 8374, 38655, 12512, 7897, 17392, 5281, 14709, 24109, 5366, 21, 27231, 32396, 7412, 49479]\n",
            "Tokens: ['<|begin_of_text|>', 'Ар', '▁аас', '▁ сылларга ', '▁үөрэнэн ', '▁ааспыт ', '▁уч', '▁ил', '▁ещ', '▁аларын ', '▁үбүлүөй', '▁үн к', '▁өрс', '▁ө к', '▁элл', '▁илэр ', '▁ыраах', '▁тан', '-', 'чуг', '▁астан ', '▁элбэх ', '▁ыалдьыт']\n",
            "\n",
            "Forward pass:\n",
            "Logits shape: torch.Size([1, 23, 50000])\n",
            "\n",
            "Embeddings:\n",
            "Embedding shape: torch.Size([1, 23, 2048])\n",
            "Mean embedding norm: 0.4007\n",
            "\n",
            "Test generation:\n",
            "Generated text: <|begin_of_text|>Ар аас  сылларга  үөрэнэн  ааспыт  уч ил ещ аларын  үбүлүөй үн к өрс ө к элл илэр  ыраах тан-чуг астан  элбэх  ыалдьыт-Ɵ-Ɵ-Ɵ-Ɵ-Ɵ-Ɵ-�\n",
            "\n",
            "========================================\n",
            "\n",
            "\n",
            "========================================\n",
            "Testing Russian text\n",
            "========================================\n",
            "\n",
            "Tokenization:\n",
            "Input text: <|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\n",
            "Token IDs: [0, 404, 4560, 21, 431, 5752, 2551, 14040, 22, 8, 402, 43539, 7537, 2551, 14040, 20, 8, 440, 8839, 7537, 6370, 47342, 12855, 10862, 4505, 13397, 13663, 14667, 2536, 4980, 16716, 5431, 19203, 2488, 2518, 34570, 10948, 4641, 4694, 22]\n",
            "Tokens: ['<|begin_of_text|>', 'Ж', '▁ил', '-', 'б', '▁ыл ', '▁ц', '▁арь', '.', ' ', 'Д', '▁обр', '▁ый ', '▁ц', '▁арь', ',', ' ', 'к', '▁отор', '▁ый ', '▁оч', '▁ень ', '▁лю', '▁бил', '▁ с', '▁во', '▁их ', '▁под', '▁д', '▁анн', '▁ых ', '▁и б', '▁ыл с', '▁ ', '▁н', '▁ими ', '▁ла', '▁ск', '▁ов', '.']\n",
            "\n",
            "Forward pass:\n",
            "Logits shape: torch.Size([1, 40, 50000])\n",
            "\n",
            "Embeddings:\n",
            "Embedding shape: torch.Size([1, 40, 2048])\n",
            "Mean embedding norm: 0.4209\n",
            "\n",
            "Test generation:\n",
            "Generated text: <|begin_of_text|>Ж ил-б ыл  ц арь. Д обр ый  ц арь, к отор ый  оч ень  лю бил  с во их  под д анн ых  и б ыл с   н ими  ла ск ов.<|end_of_text|> 2008.8.8.8.8.8.8.8.8\n",
            "\n",
            "========================================\n",
            "\n",
            "\n",
            "========================================\n",
            "Testing English text\n",
            "========================================\n",
            "\n",
            "Tokenization:\n",
            "Input text: <|begin_of_text|>Once upon a time there was a king. A kind king who loved his subjects dearly.\n",
            "Token IDs: [0, 12496, 4551, 8245, 4927, 21194, 5795, 22, 8, 6903, 6211, 5795, 5874, 5610, 10852, 9789, 28780, 8068, 5130, 22]\n",
            "Tokens: ['<|begin_of_text|>', 'Once ', '▁up', '▁on a ', '▁time ', '▁there was a ', '▁king', '.', ' ', 'A ', '▁kind ', '▁king', '▁ who ', '▁lov', '▁ed his ', '▁sub', '▁jects ', '▁dear', '▁ly', '.']\n",
            "\n",
            "Forward pass:\n",
            "Logits shape: torch.Size([1, 20, 50000])\n",
            "\n",
            "Embeddings:\n",
            "Embedding shape: torch.Size([1, 20, 2048])\n",
            "Mean embedding norm: 0.4303\n",
            "\n",
            "Test generation:\n",
            "Generated text: <|begin_of_text|>Once  up on a  time  there was a  king. A  kind  king  who  lov ed his  sub jects  dear ly.<|end_of_text|><|begin_of_text|> 2016, 2012, 2013, 2014, 201\n",
            "\n",
            "========================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tokenization Trail using trail 2 Multilingual Tokenizer; decent tokenization.     \n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load your custom model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\"yakut-llama-model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"yakut-llama-model\")\n",
        "\n",
        "# Test texts in different languages\n",
        "test_texts = {\n",
        "    \"Yakut\": \"<|begin_of_text|>Араас сылларга үөрэнэн ааспыт училещаларын үбүлүөйүн көрсө кэллилэр ыраахтан-чугастан элбэх ыалдьыт\",\n",
        "    \"Russian\": \"<|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\",\n",
        "    \"English\": \"<|begin_of_text|>Once upon a time there was a king. A kind king who loved his subjects dearly.\"\n",
        "}\n",
        "\n",
        "# Run tests for each language\n",
        "for lang, text in test_texts.items():\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"Testing {lang} text\")\n",
        "    print(f\"{'='*40}\")\n",
        "    \n",
        "    # Tokenization test\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    \n",
        "    print(\"\\nTokenization:\")\n",
        "    print(f\"Input text: {text}\")\n",
        "    print(f\"Token IDs: {inputs['input_ids'].tolist()[0]}\")\n",
        "    print(f\"Tokens: {tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])}\")\n",
        "    \n",
        "    # Forward pass test\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    \n",
        "    print(\"\\nForward pass:\")\n",
        "    print(f\"Logits shape: {outputs.logits.shape}\")  # Should be [1, seq_len, vocab_size]\n",
        "    \n",
        "    # Embedding test\n",
        "    input_embeds = model.get_input_embeddings()(inputs.input_ids)\n",
        "    print(\"\\nEmbeddings:\")\n",
        "    print(f\"Embedding shape: {input_embeds.shape}\")\n",
        "    print(f\"Mean embedding norm: {torch.norm(input_embeds, dim=2).mean().item():.4f}\")\n",
        "    \n",
        "    # Test generation\n",
        "    print(\"\\nTest generation:\")\n",
        "    with torch.no_grad():\n",
        "        generated = model.generate(\n",
        "            inputs.input_ids,\n",
        "            attention_mask=inputs.attention_mask,\n",
        "            max_new_tokens=20,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=tokenizer.pad_token_id\n",
        "        )\n",
        "        decoded = tokenizer.decode(generated[0], skip_special_tokens=False)\n",
        "        print(f\"Generated text: {decoded}\")\n",
        "    \n",
        "    print(f\"\\n{'='*40}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TOKENIZATION ANALYSIS: YAKUT\n",
            "============================================================\n",
            "\n",
            "Original text (116 chars):\n",
            "<|begin_of_text|>Араас сылларга үөрэнэн ааспыт училещаларын үбүлүөйүн көрсө кэллилэр ыраахтан-чугастан элбэх ыалдьыт\n",
            "\n",
            "Tokens (23 tokens, ratio: 5.04 chars/token):\n",
            "  0: <|begin_of_text|>\n",
            "  1: Ар\n",
            "  2: ▁аас\n",
            "  3: ▁ сылларга \n",
            "  4: ▁үөрэнэн \n",
            "  5: ▁ааспыт \n",
            "  6: ▁уч\n",
            "  7: ▁ил\n",
            "  8: ▁ещ\n",
            "  9: ▁аларын \n",
            " 10: ▁үбүлүөй\n",
            " 11: ▁үн к\n",
            " 12: ▁өрс\n",
            " 13: ▁ө к\n",
            " 14: ▁элл\n",
            " 15: ▁илэр \n",
            " 16: ▁ыраах\n",
            " 17: ▁тан\n",
            " 18: -\n",
            " 19: чуг\n",
            " 20: ▁астан \n",
            " 21: ▁элбэх \n",
            " 22: ▁ыалдьыт\n",
            "\n",
            "Reconstructed text:\n",
            "<|begin_of_text|>Ар аас  сылларга  үөрэнэн  ааспыт  уч ил ещ аларын  үбүлүөй үн к өрс ө к элл илэр  ыраах тан-чуг астан  элбэх  ыалдьыт\n",
            "Perfect reconstruction: False\n",
            "\n",
            "Warning: Problematic tokens detected:\n",
            "['-']\n",
            "\n",
            "============================================================\n",
            "TOKENIZATION ANALYSIS: RUSSIAN\n",
            "============================================================\n",
            "\n",
            "Original text (100 chars):\n",
            "<|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\n",
            "\n",
            "Tokens (40 tokens, ratio: 2.50 chars/token):\n",
            "  0: <|begin_of_text|>\n",
            "  1: Ж\n",
            "  2: ▁ил\n",
            "  3: -\n",
            "  4: б\n",
            "  5: ▁ыл \n",
            "  6: ▁ц\n",
            "  7: ▁арь\n",
            "  8: .\n",
            "  9:  \n",
            " 10: Д\n",
            " 11: ▁обр\n",
            " 12: ▁ый \n",
            " 13: ▁ц\n",
            " 14: ▁арь\n",
            " 15: ,\n",
            " 16:  \n",
            " 17: к\n",
            " 18: ▁отор\n",
            " 19: ▁ый \n",
            " 20: ▁оч\n",
            " 21: ▁ень \n",
            " 22: ▁лю\n",
            " 23: ▁бил\n",
            " 24: ▁ с\n",
            " 25: ▁во\n",
            " 26: ▁их \n",
            " 27: ▁под\n",
            " 28: ▁д\n",
            " 29: ▁анн\n",
            " 30: ▁ых \n",
            " 31: ▁и б\n",
            " 32: ▁ыл с\n",
            " 33: ▁ \n",
            " 34: ▁н\n",
            " 35: ▁ими \n",
            " 36: ▁ла\n",
            " 37: ▁ск\n",
            " 38: ▁ов\n",
            " 39: .\n",
            "\n",
            "Reconstructed text:\n",
            "<|begin_of_text|>Ж ил-б ыл  ц арь. Д обр ый  ц арь, к отор ый  оч ень  лю бил  с во их  под д анн ых  и б ыл с   н ими  ла ск ов.\n",
            "Perfect reconstruction: False\n",
            "\n",
            "Warning: Problematic tokens detected:\n",
            "['Ж', '-', 'б', '.', ' ', 'Д', ',', ' ', 'к', '.']\n",
            "\n",
            "============================================================\n",
            "TOKENIZATION ANALYSIS: ENGLISH\n",
            "============================================================\n",
            "\n",
            "Original text (94 chars):\n",
            "<|begin_of_text|>Once upon a time there was a king. A kind king who loved his subjects dearly.\n",
            "\n",
            "Tokens (20 tokens, ratio: 4.70 chars/token):\n",
            "  0: <|begin_of_text|>\n",
            "  1: Once \n",
            "  2: ▁up\n",
            "  3: ▁on a \n",
            "  4: ▁time \n",
            "  5: ▁there was a \n",
            "  6: ▁king\n",
            "  7: .\n",
            "  8:  \n",
            "  9: A \n",
            " 10: ▁kind \n",
            " 11: ▁king\n",
            " 12: ▁ who \n",
            " 13: ▁lov\n",
            " 14: ▁ed his \n",
            " 15: ▁sub\n",
            " 16: ▁jects \n",
            " 17: ▁dear\n",
            " 18: ▁ly\n",
            " 19: .\n",
            "\n",
            "Reconstructed text:\n",
            "<|begin_of_text|>Once  up on a  time  there was a  king. A  kind  king  who  lov ed his  sub jects  dear ly.\n",
            "Perfect reconstruction: False\n",
            "\n",
            "Warning: Problematic tokens detected:\n",
            "['.', ' ', '.']\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import os\n",
        "\n",
        "# Load your custom tokenizer\n",
        "tokenizer_path = \"yakut-llama-model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "def analyze_tokenization(text, tokenizer):\n",
        "    # Encode the text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "    \n",
        "    # Calculate metrics\n",
        "    char_count = len(text)\n",
        "    token_count = len(tokens)\n",
        "    compression_ratio = char_count / token_count\n",
        "    \n",
        "    # Reconstruct text from tokens\n",
        "    reconstructed = tokenizer.decode(inputs['input_ids'][0])\n",
        "    \n",
        "    return {\n",
        "        \"original\": text,\n",
        "        \"tokens\": tokens,\n",
        "        \"token_count\": token_count,\n",
        "        \"char_count\": char_count,\n",
        "        \"compression_ratio\": compression_ratio,\n",
        "        \"reconstructed\": reconstructed,\n",
        "        \"perfect_reconstruction\": text == reconstructed\n",
        "    }\n",
        "\n",
        "def print_tokenization_report(report):\n",
        "    print(f\"\\nOriginal text ({report['char_count']} chars):\")\n",
        "    print(report['original'])\n",
        "    \n",
        "    print(f\"\\nTokens ({report['token_count']} tokens, ratio: {report['compression_ratio']:.2f} chars/token):\")\n",
        "    for i, token in enumerate(report['tokens']):\n",
        "        print(f\"{i:3d}: {token}\")\n",
        "    \n",
        "    print(\"\\nReconstructed text:\")\n",
        "    print(report['reconstructed'])\n",
        "    print(f\"Perfect reconstruction: {report['perfect_reconstruction']}\")\n",
        "    \n",
        "    # Highlight problematic tokens\n",
        "    problem_tokens = [token for token in report['tokens'] if len(token) == 1 or '�' in token]\n",
        "    if problem_tokens:\n",
        "        print(\"\\nWarning: Problematic tokens detected:\")\n",
        "        print(problem_tokens)\n",
        "\n",
        "# Test texts\n",
        "test_texts = {\n",
        "    \"Yakut\": \"<|begin_of_text|>Араас сылларга үөрэнэн ааспыт училещаларын үбүлүөйүн көрсө кэллилэр ыраахтан-чугастан элбэх ыалдьыт\",\n",
        "    \"Russian\": \"<|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\",\n",
        "    \"English\": \"<|begin_of_text|>Once upon a time there was a king. A kind king who loved his subjects dearly.\"\n",
        "}\n",
        "\n",
        "# Run analysis\n",
        "for lang, text in test_texts.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"TOKENIZATION ANALYSIS: {lang.upper()}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    report = analyze_tokenization(text, tokenizer)\n",
        "    print_tokenization_report(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Login to Hugging Face\n",
        "login(token=\"hf_iwTFtLrOyizDmnYjwmlGCLwGMhOADK\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKII0aOne-9O"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2b3e9718a014690b2c7287d9430cf2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "447b75b6ae534adcb0884c042e16b4ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c3f78cd69444b92a54564cbb48329c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original vocab size: 128256\n",
            "New vocab size: 50000\n",
            "\n",
            "Creating new embeddings...\n",
            "\n",
            "Custom model saved to: yakut-llama-model\n",
            "\n",
            "Test inference:\n",
            "Logits shape: torch.Size([1, 6, 50000])\n",
            "Generated text: <|begin_of_text|>Мин  аатым  К эскил.Indo,Indo,Indo,Indo,Indo,Indo,Indo\n"
          ]
        }
      ],
      "source": [
        "#Trail 2: Multilingual Tokenizer; decent tokenization. \n",
        "\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# 1. Load your Yakut tokenizer\n",
        "tokenizer_path = \"/Users/abu/Downloads/CustomLlamaTok/yakut_tokenizer\"\n",
        "yakut_tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "# 2. Load Llama 3 model and tokenizer\n",
        "model_name = \"meta-llama/Llama-3.2-1B\"\n",
        "token = \"hf_ynsefXAVByqhClmLjMARNwGQJkBikq\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    token=token\n",
        ")\n",
        "\n",
        "# Load the ORIGINAL tokenizer for Llama\n",
        "original_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    token=token\n",
        ")\n",
        "\n",
        "# 3. Get vocabulary sizes\n",
        "original_vocab_size = model.config.vocab_size\n",
        "new_vocab_size = len(yakut_tokenizer)\n",
        "print(f\"Original vocab size: {original_vocab_size}\")\n",
        "print(f\"New vocab size: {new_vocab_size}\")\n",
        "\n",
        "# 4. Create new embedding matrix\n",
        "print(\"\\nCreating new embeddings...\")\n",
        "with torch.no_grad():\n",
        "    # Get original embeddings\n",
        "    original_embeddings = model.get_input_embeddings().weight.data.clone()\n",
        "    mean_embedding = original_embeddings.mean(dim=0)\n",
        "    \n",
        "    # Create new embedding layer\n",
        "    new_embeddings = torch.nn.Embedding(new_vocab_size, model.config.hidden_size)\n",
        "    \n",
        "    # Get vocabulary of the original tokenizer\n",
        "    original_vocab = original_tokenizer.get_vocab()\n",
        "    \n",
        "    # Copy embeddings for overlapping tokens\n",
        "    for token, new_idx in yakut_tokenizer.get_vocab().items():\n",
        "        # Check if token exists in original tokenizer\n",
        "        if token in original_vocab:\n",
        "            old_idx = original_vocab[token]\n",
        "            new_embeddings.weight[new_idx] = original_embeddings[old_idx].clone()\n",
        "        else:\n",
        "            # For new tokens, use mean embedding\n",
        "            new_embeddings.weight[new_idx] = mean_embedding\n",
        "    \n",
        "    # Replace model embeddings\n",
        "    model.set_input_embeddings(new_embeddings)\n",
        "    \n",
        "    # Update config\n",
        "    model.config.vocab_size = new_vocab_size\n",
        "    \n",
        "    # Tie weights if needed\n",
        "    if model.config.tie_word_embeddings:\n",
        "        model.lm_head.weight = model.get_input_embeddings().weight\n",
        "\n",
        "# 5. Save the custom model\n",
        "save_path = \"yakut-llama-model\"\n",
        "model.save_pretrained(save_path)\n",
        "yakut_tokenizer.save_pretrained(save_path)\n",
        "print(f\"\\nCustom model saved to: {save_path}\")\n",
        "\n",
        "# 6. Test the model with proper settings\n",
        "test_text = \"<|begin_of_text|>Мин аатым Кэскил.\"\n",
        "inputs = yakut_tokenizer(test_text, return_tensors=\"pt\")\n",
        "\n",
        "# Set pad token if not set\n",
        "if yakut_tokenizer.pad_token is None:\n",
        "    yakut_tokenizer.pad_token = yakut_tokenizer.eos_token\n",
        "    model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "print(\"\\nTest inference:\")\n",
        "with torch.no_grad():\n",
        "    # Forward pass\n",
        "    outputs = model(**inputs)\n",
        "    print(f\"Logits shape: {outputs.logits.shape}\")\n",
        "    \n",
        "    # Test generation with attention mask\n",
        "    generated = model.generate(\n",
        "        inputs.input_ids,\n",
        "        attention_mask=inputs.attention_mask,\n",
        "        max_new_tokens=20,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=yakut_tokenizer.pad_token_id\n",
        "    )\n",
        "    decoded = yakut_tokenizer.decode(generated[0], skip_special_tokens=False)\n",
        "    print(f\"Generated text: {decoded}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap3vQQQpZzVd"
      },
      "source": [
        "**RUSSIAN**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294,
          "referenced_widgets": [
            "32e48ed387c34465bc814dc9f82d2da4",
            "0dc23beff0384ec19ab41ea5c4a44c51",
            "398ba5b628b945d9892c71fb25aae7f6",
            "1af7793d447c4524a9849e055ecd6e2b",
            "cddf9b4df5c54841885f9cfbcc696610",
            "cd130aaab5244a3eacabe96de3bf89d4",
            "99babf8361454f5c934aaec7d01b3471",
            "19fdccfa801c4debb4d8d7e2b02235cd",
            "f8adb68abc34448e9296a7ac6b77df23",
            "9347cb76ea744bec8eb0736bb6494aa8",
            "3f3049ba11564571b56bf8d5ebf94b15"
          ]
        },
        "id": "mk78CskPZsj2",
        "outputId": "f3e7d152-610c-4b6b-eafa-1f2161aa99fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32e48ed387c34465bc814dc9f82d2da4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenization test:\n",
            "Input text: <|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\n",
            "Token IDs: [0, 2696, 1031, 17, 3091, 4415, 8687, 18, 1138, 20195, 1162, 4415, 8687, 16, 20548, 1162, 4498, 6162, 18406, 3685, 17454, 4297, 4450, 382, 1197, 10381, 1058, 1401, 1009, 1121, 20132, 1388, 25376, 18]\n",
            "Tokens: ['<|begin_of_text|>', '▁Ж', 'ил', '-', 'был', '▁ц', 'арь', '.', '▁Д', 'обр', 'ый', '▁ц', 'арь', ',', '▁котор', 'ый', '▁оч', 'ень', '▁лю', 'бил', '▁сво', 'их', '▁под', 'д', 'анн', 'ых', '▁и', '▁был', '▁с', '▁н', 'ими', '▁л', 'асков', '.']\n",
            "\n",
            "Forward pass test:\n",
            "Logits shape: torch.Size([1, 34, 30000])\n",
            "Forward pass successful!\n",
            "\n",
            "Embedding test:\n",
            "Embedding shape: torch.Size([1, 34, 4096])\n",
            "Embedding norms: 0.5088\n"
          ]
        }
      ],
      "source": [
        "# Tokenization Trail using trail 1 Multilingual Tokenizer; Suboptimal tokenization.     \n",
        "\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "\n",
        "# Load your custom model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\"yakut-llama-model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"yakut-llama-model\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Test tokenization\n",
        "text = \"<|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "print(\"Tokenization test:\")\n",
        "print(f\"Input text: {text}\")\n",
        "print(f\"Token IDs: {inputs['input_ids'].tolist()[0]}\")\n",
        "print(f\"Tokens: {tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])}\")\n",
        "\n",
        "# Test forward pass\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "print(\"\\nForward pass test:\")\n",
        "print(f\"Logits shape: {outputs.logits.shape}\")  # Should be [1, seq_len, vocab_size]\n",
        "print(\"Forward pass successful!\")\n",
        "\n",
        "# Test embedding layer\n",
        "input_embeds = model.get_input_embeddings()(inputs.input_ids)\n",
        "print(f\"\\nEmbedding test:\")\n",
        "print(f\"Embedding shape: {input_embeds.shape}\")  # Should be [1, seq_len, hidden_size]\n",
        "print(f\"Embedding norms: {torch.norm(input_embeds, dim=2).mean().item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "Testing Yakut text\n",
            "========================================\n",
            "\n",
            "Tokenization:\n",
            "Input text: <|begin_of_text|>Араас сылларга үөрэнэн ааспыт училещаларын үбүлүөйүн көрсө кэллилэр ыраахтан-чугастан элбэх ыалдьыт\n",
            "Token IDs: [0, 7931, 5567, 16944, 16780, 17172, 5546, 4560, 49601, 8374, 38655, 12512, 7897, 17392, 5281, 14709, 24109, 5366, 21, 27231, 32396, 7412, 49479]\n",
            "Tokens: ['<|begin_of_text|>', 'Ар', '▁аас', '▁ сылларга ', '▁үөрэнэн ', '▁ааспыт ', '▁уч', '▁ил', '▁ещ', '▁аларын ', '▁үбүлүөй', '▁үн к', '▁өрс', '▁ө к', '▁элл', '▁илэр ', '▁ыраах', '▁тан', '-', 'чуг', '▁астан ', '▁элбэх ', '▁ыалдьыт']\n",
            "\n",
            "Forward pass:\n",
            "Logits shape: torch.Size([1, 23, 50000])\n",
            "\n",
            "Embeddings:\n",
            "Embedding shape: torch.Size([1, 23, 2048])\n",
            "Mean embedding norm: 0.4007\n",
            "\n",
            "Test generation:\n",
            "Generated text: <|begin_of_text|>Ар аас  сылларга  үөрэнэн  ааспыт  уч ил ещ аларын  үбүлүөй үн к өрс ө к элл илэр  ыраах тан-чуг астан  элбэх  ыалдьыт-Ɵ-Ɵ-Ɵ-Ɵ-Ɵ-Ɵ-�\n",
            "\n",
            "========================================\n",
            "\n",
            "\n",
            "========================================\n",
            "Testing Russian text\n",
            "========================================\n",
            "\n",
            "Tokenization:\n",
            "Input text: <|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\n",
            "Token IDs: [0, 404, 4560, 21, 431, 5752, 2551, 14040, 22, 8, 402, 43539, 7537, 2551, 14040, 20, 8, 440, 8839, 7537, 6370, 47342, 12855, 10862, 4505, 13397, 13663, 14667, 2536, 4980, 16716, 5431, 19203, 2488, 2518, 34570, 10948, 4641, 4694, 22]\n",
            "Tokens: ['<|begin_of_text|>', 'Ж', '▁ил', '-', 'б', '▁ыл ', '▁ц', '▁арь', '.', ' ', 'Д', '▁обр', '▁ый ', '▁ц', '▁арь', ',', ' ', 'к', '▁отор', '▁ый ', '▁оч', '▁ень ', '▁лю', '▁бил', '▁ с', '▁во', '▁их ', '▁под', '▁д', '▁анн', '▁ых ', '▁и б', '▁ыл с', '▁ ', '▁н', '▁ими ', '▁ла', '▁ск', '▁ов', '.']\n",
            "\n",
            "Forward pass:\n",
            "Logits shape: torch.Size([1, 40, 50000])\n",
            "\n",
            "Embeddings:\n",
            "Embedding shape: torch.Size([1, 40, 2048])\n",
            "Mean embedding norm: 0.4209\n",
            "\n",
            "Test generation:\n",
            "Generated text: <|begin_of_text|>Ж ил-б ыл  ц арь. Д обр ый  ц арь, к отор ый  оч ень  лю бил  с во их  под д анн ых  и б ыл с   н ими  ла ск ов.<|end_of_text|> 2008.8.8.8.8.8.8.8.8\n",
            "\n",
            "========================================\n",
            "\n",
            "\n",
            "========================================\n",
            "Testing English text\n",
            "========================================\n",
            "\n",
            "Tokenization:\n",
            "Input text: <|begin_of_text|>Once upon a time there was a king. A kind king who loved his subjects dearly.\n",
            "Token IDs: [0, 12496, 4551, 8245, 4927, 21194, 5795, 22, 8, 6903, 6211, 5795, 5874, 5610, 10852, 9789, 28780, 8068, 5130, 22]\n",
            "Tokens: ['<|begin_of_text|>', 'Once ', '▁up', '▁on a ', '▁time ', '▁there was a ', '▁king', '.', ' ', 'A ', '▁kind ', '▁king', '▁ who ', '▁lov', '▁ed his ', '▁sub', '▁jects ', '▁dear', '▁ly', '.']\n",
            "\n",
            "Forward pass:\n",
            "Logits shape: torch.Size([1, 20, 50000])\n",
            "\n",
            "Embeddings:\n",
            "Embedding shape: torch.Size([1, 20, 2048])\n",
            "Mean embedding norm: 0.4303\n",
            "\n",
            "Test generation:\n",
            "Generated text: <|begin_of_text|>Once  up on a  time  there was a  king. A  kind  king  who  lov ed his  sub jects  dear ly.<|end_of_text|><|begin_of_text|> 2016, 2012, 2013, 2014, 201\n",
            "\n",
            "========================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tokenization Trail using trail 2 Multilingual Tokenizer; decent tokenization.     \n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load your custom model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\"yakut-llama-model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"yakut-llama-model\")\n",
        "\n",
        "# Test texts in different languages\n",
        "test_texts = {\n",
        "    \"Yakut\": \"<|begin_of_text|>Араас сылларга үөрэнэн ааспыт училещаларын үбүлүөйүн көрсө кэллилэр ыраахтан-чугастан элбэх ыалдьыт\",\n",
        "    \"Russian\": \"<|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\",\n",
        "    \"English\": \"<|begin_of_text|>Once upon a time there was a king. A kind king who loved his subjects dearly.\"\n",
        "}\n",
        "\n",
        "# Run tests for each language\n",
        "for lang, text in test_texts.items():\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"Testing {lang} text\")\n",
        "    print(f\"{'='*40}\")\n",
        "    \n",
        "    # Tokenization test\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    \n",
        "    print(\"\\nTokenization:\")\n",
        "    print(f\"Input text: {text}\")\n",
        "    print(f\"Token IDs: {inputs['input_ids'].tolist()[0]}\")\n",
        "    print(f\"Tokens: {tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])}\")\n",
        "    \n",
        "    # Forward pass test\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    \n",
        "    print(\"\\nForward pass:\")\n",
        "    print(f\"Logits shape: {outputs.logits.shape}\")  # Should be [1, seq_len, vocab_size]\n",
        "    \n",
        "    # Embedding test\n",
        "    input_embeds = model.get_input_embeddings()(inputs.input_ids)\n",
        "    print(\"\\nEmbeddings:\")\n",
        "    print(f\"Embedding shape: {input_embeds.shape}\")\n",
        "    print(f\"Mean embedding norm: {torch.norm(input_embeds, dim=2).mean().item():.4f}\")\n",
        "    \n",
        "    # Test generation\n",
        "    print(\"\\nTest generation:\")\n",
        "    with torch.no_grad():\n",
        "        generated = model.generate(\n",
        "            inputs.input_ids,\n",
        "            attention_mask=inputs.attention_mask,\n",
        "            max_new_tokens=20,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=tokenizer.pad_token_id\n",
        "        )\n",
        "        decoded = tokenizer.decode(generated[0], skip_special_tokens=False)\n",
        "        print(f\"Generated text: {decoded}\")\n",
        "    \n",
        "    print(f\"\\n{'='*40}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TOKENIZATION ANALYSIS: YAKUT\n",
            "============================================================\n",
            "\n",
            "Original text (116 chars):\n",
            "<|begin_of_text|>Араас сылларга үөрэнэн ааспыт училещаларын үбүлүөйүн көрсө кэллилэр ыраахтан-чугастан элбэх ыалдьыт\n",
            "\n",
            "Tokens (23 tokens, ratio: 5.04 chars/token):\n",
            "  0: <|begin_of_text|>\n",
            "  1: Ар\n",
            "  2: ▁аас\n",
            "  3: ▁ сылларга \n",
            "  4: ▁үөрэнэн \n",
            "  5: ▁ааспыт \n",
            "  6: ▁уч\n",
            "  7: ▁ил\n",
            "  8: ▁ещ\n",
            "  9: ▁аларын \n",
            " 10: ▁үбүлүөй\n",
            " 11: ▁үн к\n",
            " 12: ▁өрс\n",
            " 13: ▁ө к\n",
            " 14: ▁элл\n",
            " 15: ▁илэр \n",
            " 16: ▁ыраах\n",
            " 17: ▁тан\n",
            " 18: -\n",
            " 19: чуг\n",
            " 20: ▁астан \n",
            " 21: ▁элбэх \n",
            " 22: ▁ыалдьыт\n",
            "\n",
            "Reconstructed text:\n",
            "<|begin_of_text|>Ар аас  сылларга  үөрэнэн  ааспыт  уч ил ещ аларын  үбүлүөй үн к өрс ө к элл илэр  ыраах тан-чуг астан  элбэх  ыалдьыт\n",
            "Perfect reconstruction: False\n",
            "\n",
            "Warning: Problematic tokens detected:\n",
            "['-']\n",
            "\n",
            "============================================================\n",
            "TOKENIZATION ANALYSIS: RUSSIAN\n",
            "============================================================\n",
            "\n",
            "Original text (100 chars):\n",
            "<|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\n",
            "\n",
            "Tokens (40 tokens, ratio: 2.50 chars/token):\n",
            "  0: <|begin_of_text|>\n",
            "  1: Ж\n",
            "  2: ▁ил\n",
            "  3: -\n",
            "  4: б\n",
            "  5: ▁ыл \n",
            "  6: ▁ц\n",
            "  7: ▁арь\n",
            "  8: .\n",
            "  9:  \n",
            " 10: Д\n",
            " 11: ▁обр\n",
            " 12: ▁ый \n",
            " 13: ▁ц\n",
            " 14: ▁арь\n",
            " 15: ,\n",
            " 16:  \n",
            " 17: к\n",
            " 18: ▁отор\n",
            " 19: ▁ый \n",
            " 20: ▁оч\n",
            " 21: ▁ень \n",
            " 22: ▁лю\n",
            " 23: ▁бил\n",
            " 24: ▁ с\n",
            " 25: ▁во\n",
            " 26: ▁их \n",
            " 27: ▁под\n",
            " 28: ▁д\n",
            " 29: ▁анн\n",
            " 30: ▁ых \n",
            " 31: ▁и б\n",
            " 32: ▁ыл с\n",
            " 33: ▁ \n",
            " 34: ▁н\n",
            " 35: ▁ими \n",
            " 36: ▁ла\n",
            " 37: ▁ск\n",
            " 38: ▁ов\n",
            " 39: .\n",
            "\n",
            "Reconstructed text:\n",
            "<|begin_of_text|>Ж ил-б ыл  ц арь. Д обр ый  ц арь, к отор ый  оч ень  лю бил  с во их  под д анн ых  и б ыл с   н ими  ла ск ов.\n",
            "Perfect reconstruction: False\n",
            "\n",
            "Warning: Problematic tokens detected:\n",
            "['Ж', '-', 'б', '.', ' ', 'Д', ',', ' ', 'к', '.']\n",
            "\n",
            "============================================================\n",
            "TOKENIZATION ANALYSIS: ENGLISH\n",
            "============================================================\n",
            "\n",
            "Original text (94 chars):\n",
            "<|begin_of_text|>Once upon a time there was a king. A kind king who loved his subjects dearly.\n",
            "\n",
            "Tokens (20 tokens, ratio: 4.70 chars/token):\n",
            "  0: <|begin_of_text|>\n",
            "  1: Once \n",
            "  2: ▁up\n",
            "  3: ▁on a \n",
            "  4: ▁time \n",
            "  5: ▁there was a \n",
            "  6: ▁king\n",
            "  7: .\n",
            "  8:  \n",
            "  9: A \n",
            " 10: ▁kind \n",
            " 11: ▁king\n",
            " 12: ▁ who \n",
            " 13: ▁lov\n",
            " 14: ▁ed his \n",
            " 15: ▁sub\n",
            " 16: ▁jects \n",
            " 17: ▁dear\n",
            " 18: ▁ly\n",
            " 19: .\n",
            "\n",
            "Reconstructed text:\n",
            "<|begin_of_text|>Once  up on a  time  there was a  king. A  kind  king  who  lov ed his  sub jects  dear ly.\n",
            "Perfect reconstruction: False\n",
            "\n",
            "Warning: Problematic tokens detected:\n",
            "['.', ' ', '.']\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import os\n",
        "\n",
        "# Load your custom tokenizer\n",
        "tokenizer_path = \"yakut-llama-model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "def analyze_tokenization(text, tokenizer):\n",
        "    # Encode the text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "    \n",
        "    # Calculate metrics\n",
        "    char_count = len(text)\n",
        "    token_count = len(tokens)\n",
        "    compression_ratio = char_count / token_count\n",
        "    \n",
        "    # Reconstruct text from tokens\n",
        "    reconstructed = tokenizer.decode(inputs['input_ids'][0])\n",
        "    \n",
        "    return {\n",
        "        \"original\": text,\n",
        "        \"tokens\": tokens,\n",
        "        \"token_count\": token_count,\n",
        "        \"char_count\": char_count,\n",
        "        \"compression_ratio\": compression_ratio,\n",
        "        \"reconstructed\": reconstructed,\n",
        "        \"perfect_reconstruction\": text == reconstructed\n",
        "    }\n",
        "\n",
        "def print_tokenization_report(report):\n",
        "    print(f\"\\nOriginal text ({report['char_count']} chars):\")\n",
        "    print(report['original'])\n",
        "    \n",
        "    print(f\"\\nTokens ({report['token_count']} tokens, ratio: {report['compression_ratio']:.2f} chars/token):\")\n",
        "    for i, token in enumerate(report['tokens']):\n",
        "        print(f\"{i:3d}: {token}\")\n",
        "    \n",
        "    print(\"\\nReconstructed text:\")\n",
        "    print(report['reconstructed'])\n",
        "    print(f\"Perfect reconstruction: {report['perfect_reconstruction']}\")\n",
        "    \n",
        "    # Highlight problematic tokens\n",
        "    problem_tokens = [token for token in report['tokens'] if len(token) == 1 or '�' in token]\n",
        "    if problem_tokens:\n",
        "        print(\"\\nWarning: Problematic tokens detected:\")\n",
        "        print(problem_tokens)\n",
        "\n",
        "# Test texts\n",
        "test_texts = {\n",
        "    \"Yakut\": \"<|begin_of_text|>Араас сылларга үөрэнэн ааспыт училещаларын үбүлүөйүн көрсө кэллилэр ыраахтан-чугастан элбэх ыалдьыт\",\n",
        "    \"Russian\": \"<|begin_of_text|>Жил-был царь. Добрый царь, который очень любил своих подданных и был с ними ласков.\",\n",
        "    \"English\": \"<|begin_of_text|>Once upon a time there was a king. A kind king who loved his subjects dearly.\"\n",
        "}\n",
        "\n",
        "# Run analysis\n",
        "for lang, text in test_texts.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"TOKENIZATION ANALYSIS: {lang.upper()}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    report = analyze_tokenization(text, tokenizer)\n",
        "    print_tokenization_report(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00a0d988d0de498e8c1b3ff5109a6eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68353c3bbe04492fab075af2291b4953",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13f03181eef7426f8123e56c86938b5a",
            "value": 6
          }
        },
        "029b06fa59274bcea9d8d03d8d47d82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d310e606ec584b5ab5b34f68a40bde2c",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_409850fac2a24fcba5af3fcdeeefb948",
            "value": 4
          }
        },
        "02a46aa5fcee4adeb1992864d828e7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "044ff251f3ed44069ac5a54dea5e46d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04fa05e826f6460788adf43afa91ebb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0939530ab2bb4716b18d1d1c8dba7bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0975f0f594f441ff81dbb4cbbbb63bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6498525e569a41c7867124d6f7379497",
            "placeholder": "​",
            "style": "IPY_MODEL_ade0503b40d74bd19a47d195c1084176",
            "value": " 6/6 [00:00&lt;00:00, 88.30it/s]"
          }
        },
        "0a2177b8c55346bcba826e750a6b9397": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a91659b6f4c495da026db8849f0b442": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f985c31c354c499488d99d707ce0b8c5",
              "IPY_MODEL_2d3ebaa8835a46d8a7c54ec69f18480d",
              "IPY_MODEL_9109e6f18e2e4125b5466d4b51a06b6e"
            ],
            "layout": "IPY_MODEL_69778e1c822b440d81de14476d06f8a7"
          }
        },
        "0d46e0f5a461405291212211b9140d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0dc23beff0384ec19ab41ea5c4a44c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd130aaab5244a3eacabe96de3bf89d4",
            "placeholder": "​",
            "style": "IPY_MODEL_99babf8361454f5c934aaec7d01b3471",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0dd82b2d3363426bbb99092acc3e2c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d59e586c3ad54887bae3613aada80d5f",
              "IPY_MODEL_2c42dc0edf8245209d48556044447fda",
              "IPY_MODEL_67f7fdb4f22342a8b4a20620ac6c1df2"
            ],
            "layout": "IPY_MODEL_ca14aae9a48e4b31897c63718b6fd192"
          }
        },
        "0e196f66208d4bcc82d76d688440e9aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe61dc89049475ba8a5bed86cad063f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13f03181eef7426f8123e56c86938b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "146a385744624da4b523eee199302749": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_585c3805a0b3498d83b3b9aae069b303",
              "IPY_MODEL_e7f46b4c7b5f46a8bf74a74d54fbd672",
              "IPY_MODEL_4a69ebd3562b47b08087176f5cac0477"
            ],
            "layout": "IPY_MODEL_e170a06a5e1f47cc919475dbf9acbbf6"
          }
        },
        "16ee78b5a5424fb7bdd7466b89202cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19fdccfa801c4debb4d8d7e2b02235cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af7793d447c4524a9849e055ecd6e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9347cb76ea744bec8eb0736bb6494aa8",
            "placeholder": "​",
            "style": "IPY_MODEL_3f3049ba11564571b56bf8d5ebf94b15",
            "value": " 6/6 [00:00&lt;00:00, 75.17it/s]"
          }
        },
        "1b2b4c702ac44cb1a99409c3ddfb9b02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9be0be159b4436a4321d8cd8f25de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "290da9a273b04abeb0cdc31ebdcf303c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c27902bc000443b818139f70eb61e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e95fcc6887d84a2187a9adf49510d3c5",
            "placeholder": "​",
            "style": "IPY_MODEL_1c9be0be159b4436a4321d8cd8f25de3",
            "value": " 6/6 [00:01&lt;00:00,  7.83it/s]"
          }
        },
        "2c42dc0edf8245209d48556044447fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6df9c6341eab489c8fdd75c4e2b6aa7f",
            "max": 654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0f71c9f3ac84fd780410153e66e34f7",
            "value": 654
          }
        },
        "2cb37805de824a0f8c58923feb9960b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d3ebaa8835a46d8a7c54ec69f18480d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e9887ae36a456dae53391a16755c21",
            "max": 177,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c31747a0a924c7e9274104e6681e5ea",
            "value": 177
          }
        },
        "2dfd5c6e17374fdbb33bc3865dd67491": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63aea69e9ff04dd791e87f7a8efc39e6",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a24b3ddbd09458ebdcbc2ec9697284b",
            "value": 6
          }
        },
        "2f9fb8fd0ee44123a9a75998cbc31b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fe073da80cf41e19891642cdd40684b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1667fbc41647d0b66871f4150ad314",
            "placeholder": "​",
            "style": "IPY_MODEL_f6406d0a73eb48a7b4f8b223c38413b6",
            "value": "model-00001-of-00004.safetensors: 100%"
          }
        },
        "31282d7b60834a5eb8e110c521afaf6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e48ed387c34465bc814dc9f82d2da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0dc23beff0384ec19ab41ea5c4a44c51",
              "IPY_MODEL_398ba5b628b945d9892c71fb25aae7f6",
              "IPY_MODEL_1af7793d447c4524a9849e055ecd6e2b"
            ],
            "layout": "IPY_MODEL_cddf9b4df5c54841885f9cfbcc696610"
          }
        },
        "397d50f7c0ac451087f50aae162600cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73af0034407644e8bdc40cf89ce46103",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9ecded571b0424681218b20cc3ccbdf",
            "value": 4
          }
        },
        "398ba5b628b945d9892c71fb25aae7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19fdccfa801c4debb4d8d7e2b02235cd",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8adb68abc34448e9296a7ac6b77df23",
            "value": 6
          }
        },
        "3c0ee2b93de244749a7967e0be9dc472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cf5bdbeb89246808759594544552076": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eeb0ff03d8a40c7848e9145e74a42df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f3049ba11564571b56bf8d5ebf94b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "409850fac2a24fcba5af3fcdeeefb948": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "474ea518b7a745d78b46d130849e1a16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47afc2a2ea4e4f618f04974640a8b8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff172d6123024cf7be5ecf7e9c126c6b",
              "IPY_MODEL_5038c946efb946019b8961a8db2d5b03",
              "IPY_MODEL_a153a07481b649daa47f6259cd45bdcc"
            ],
            "layout": "IPY_MODEL_f0e487f3226b4cf9a7b551168704be0f"
          }
        },
        "49535fcd062144c6bf46fdc809c3ecb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4957eda81a764c8c8db97faa508eae07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49ab809f76424bb3ab693bbf3e3f1331": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a69ebd3562b47b08087176f5cac0477": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74c2544b34a34d1984f7f686083b621c",
            "placeholder": "​",
            "style": "IPY_MODEL_ac8e4a56233f4332ae4f44affe11786f",
            "value": " 1.17G/1.17G [00:26&lt;00:00, 53.8MB/s]"
          }
        },
        "4c1e80a700324f698ca56533b941aab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd2b8c7687ab4362bc87d03522e630a5",
              "IPY_MODEL_397d50f7c0ac451087f50aae162600cb",
              "IPY_MODEL_5dea89dd554148f69b4d74b4adaa7b7c"
            ],
            "layout": "IPY_MODEL_bd74c3257e76435e869703b0ee69d91d"
          }
        },
        "4c50c71c536c4a2185757e5e0fefc7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c8f9665f59c4c169e94320054829fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63ce635b37af45668c18c30655d703dc",
              "IPY_MODEL_029b06fa59274bcea9d8d03d8d47d82f",
              "IPY_MODEL_78df3822068e4809a539e47e8097c434"
            ],
            "layout": "IPY_MODEL_8365b150e00d43d0bffa19af8afc82bc"
          }
        },
        "4e17b98ebdba406fb14ae446b5ced02e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5038c946efb946019b8961a8db2d5b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad5f223c22b34bde95cf07d5a4d4c94f",
            "max": 4915916176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb800f5f8a394636a2f75bec4fdd8bee",
            "value": 4915916176
          }
        },
        "511662e2328a4db6a7113ef1ce153616": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "585c3805a0b3498d83b3b9aae069b303": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb2fa8b943e8448b9022ed7cd616c65b",
            "placeholder": "​",
            "style": "IPY_MODEL_f539c621d00b4394a2c626cafb0b0af7",
            "value": "model-00004-of-00004.safetensors: 100%"
          }
        },
        "58bc8312be3543c1bd92f7987b632eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe5282a2b7e34f189d8dcb370a6eaa1e",
            "placeholder": "​",
            "style": "IPY_MODEL_6be8ba69efd846ef8f5152b09862faa5",
            "value": " 23.9k/23.9k [00:00&lt;00:00, 2.36MB/s]"
          }
        },
        "5c31747a0a924c7e9274104e6681e5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dea89dd554148f69b4d74b4adaa7b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da8117e5d87b4312a5dcd43605794259",
            "placeholder": "​",
            "style": "IPY_MODEL_ece248ac57da41a0bce7422ce650c954",
            "value": " 4/4 [02:48&lt;00:00, 70.38s/it]"
          }
        },
        "601e34a60adc48199f4f1f5b95eb8e95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63aea69e9ff04dd791e87f7a8efc39e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ce635b37af45668c18c30655d703dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49ab809f76424bb3ab693bbf3e3f1331",
            "placeholder": "​",
            "style": "IPY_MODEL_db12b15823da4a3a8ef8924b93e251da",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "64419d264c8642cb87d926f30d6c54e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6498525e569a41c7867124d6f7379497": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c387c17e0a4964bcdbbe4c9acd266c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c951379fc0d4203a70b2b2a69adc88d",
            "placeholder": "​",
            "style": "IPY_MODEL_3c0ee2b93de244749a7967e0be9dc472",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "67f7fdb4f22342a8b4a20620ac6c1df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c40d8c7cf2e406db2f86d7abadf811f",
            "placeholder": "​",
            "style": "IPY_MODEL_77206df0686a47a49a4e59134ace1b02",
            "value": " 654/654 [00:00&lt;00:00, 58.2kB/s]"
          }
        },
        "68353c3bbe04492fab075af2291b4953": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69778e1c822b440d81de14476d06f8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a0083eb20c04e67af087326a78fb016": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_741ddc3e2d2c4cffa92c48026f2e8aa5",
              "IPY_MODEL_9fd0fd7a0a974e8eacb785a762a2f8d2",
              "IPY_MODEL_58bc8312be3543c1bd92f7987b632eb4"
            ],
            "layout": "IPY_MODEL_e8b3d3f8f1394d239c16ac6ffedc80cb"
          }
        },
        "6be8ba69efd846ef8f5152b09862faa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6df9c6341eab489c8fdd75c4e2b6aa7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f7492c5fb34bdc9eb898a949a2ebc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73af0034407644e8bdc40cf89ce46103": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "741ddc3e2d2c4cffa92c48026f2e8aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72f7492c5fb34bdc9eb898a949a2ebc4",
            "placeholder": "​",
            "style": "IPY_MODEL_a860eab636c344f9a89906baec61ea1d",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "74c2544b34a34d1984f7f686083b621c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77206df0686a47a49a4e59134ace1b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78df3822068e4809a539e47e8097c434": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f9fb8fd0ee44123a9a75998cbc31b3a",
            "placeholder": "​",
            "style": "IPY_MODEL_7b32df08730c4b33814342f58e944bf3",
            "value": " 4/4 [00:50&lt;00:00, 12.43s/it]"
          }
        },
        "790e15f5daac4670bc4f89d172320180": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66c387c17e0a4964bcdbbe4c9acd266c",
              "IPY_MODEL_defd5eb9abd848f5b23e0551b5a9f5a4",
              "IPY_MODEL_0975f0f594f441ff81dbb4cbbbb63bd1"
            ],
            "layout": "IPY_MODEL_ae96bb01476441939caaee6ddd847753"
          }
        },
        "7b32df08730c4b33814342f58e944bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d68c4bc50ec4cb6ada806ed02e7fd66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04fa05e826f6460788adf43afa91ebb8",
            "placeholder": "​",
            "style": "IPY_MODEL_2cb37805de824a0f8c58923feb9960b3",
            "value": " 4.98G/4.98G [02:42&lt;00:00, 53.3MB/s]"
          }
        },
        "8352186e7fd943608ef4f99886c9440b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49535fcd062144c6bf46fdc809c3ecb8",
            "placeholder": "​",
            "style": "IPY_MODEL_b1c4eb004d4a415897aaf49ab4f36d09",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8365b150e00d43d0bffa19af8afc82bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8438d56f033e45cd97e0430f6eb1d832": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84d2443e7fa1407783679f53530e5fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8807486cbdb140ee9d0225bdebe090f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_044ff251f3ed44069ac5a54dea5e46d5",
            "placeholder": "​",
            "style": "IPY_MODEL_0fe61dc89049475ba8a5bed86cad063f",
            "value": " 5.00G/5.00G [02:48&lt;00:00, 48.7MB/s]"
          }
        },
        "8a86c30abbf448ebb45171bcfa002e41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c40d8c7cf2e406db2f86d7abadf811f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed3f157c5e14168bf1d515c1a34c1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cf5bdbeb89246808759594544552076",
            "placeholder": "​",
            "style": "IPY_MODEL_fada3792c405449c90cfe70a39d5100a",
            "value": "model-00002-of-00004.safetensors: 100%"
          }
        },
        "9109e6f18e2e4125b5466d4b51a06b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f345ea9fe14f36a0eeff569d8a3a68",
            "placeholder": "​",
            "style": "IPY_MODEL_0939530ab2bb4716b18d1d1c8dba7bc1",
            "value": " 177/177 [00:00&lt;00:00, 21.7kB/s]"
          }
        },
        "91a246b0c72a4313a5742bf037720b61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9347cb76ea744bec8eb0736bb6494aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9382c7f6c4f745209173faadeb7e4ad5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99babf8361454f5c934aaec7d01b3471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a24b3ddbd09458ebdcbc2ec9697284b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c951379fc0d4203a70b2b2a69adc88d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e1667fbc41647d0b66871f4150ad314": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fd0fd7a0a974e8eacb785a762a2f8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e17b98ebdba406fb14ae446b5ced02e",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b62e48e3e5aa41119a3c741de1fde3ec",
            "value": 23950
          }
        },
        "a1167b5525a14657ac1eba6dd8787711": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da257d696c7b4df4aec14ce453cab0b5",
              "IPY_MODEL_2dfd5c6e17374fdbb33bc3865dd67491",
              "IPY_MODEL_bd8e814cf7c94ca986665aef4d7e7208"
            ],
            "layout": "IPY_MODEL_9382c7f6c4f745209173faadeb7e4ad5"
          }
        },
        "a153a07481b649daa47f6259cd45bdcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91a246b0c72a4313a5742bf037720b61",
            "placeholder": "​",
            "style": "IPY_MODEL_02a46aa5fcee4adeb1992864d828e7de",
            "value": " 4.92G/4.92G [02:43&lt;00:00, 61.7MB/s]"
          }
        },
        "a1f15797fcc34af989a23366ddb11496": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d45db72e60483db0b0b7f430385896": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ed3f157c5e14168bf1d515c1a34c1db",
              "IPY_MODEL_cd9f24a759184bbc9a3b67894e89a8b6",
              "IPY_MODEL_8807486cbdb140ee9d0225bdebe090f8"
            ],
            "layout": "IPY_MODEL_64419d264c8642cb87d926f30d6c54e5"
          }
        },
        "a4a3fb269b8a4c2b89d8b66a49355cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a860eab636c344f9a89906baec61ea1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab6c935271ad4cbfb8e10d249273a34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac8e4a56233f4332ae4f44affe11786f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad5f223c22b34bde95cf07d5a4d4c94f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade0503b40d74bd19a47d195c1084176": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae96bb01476441939caaee6ddd847753": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afad3a65be574363be3ace3c601fe6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f71c9f3ac84fd780410153e66e34f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1c4eb004d4a415897aaf49ab4f36d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3aabf1033b94e8eabcb9e3ff161e923": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fe073da80cf41e19891642cdd40684b",
              "IPY_MODEL_ca2c0638a0d042edbf5a63f09bbaf584",
              "IPY_MODEL_7d68c4bc50ec4cb6ada806ed02e7fd66"
            ],
            "layout": "IPY_MODEL_474ea518b7a745d78b46d130849e1a16"
          }
        },
        "b62e48e3e5aa41119a3c741de1fde3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8e9887ae36a456dae53391a16755c21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd74c3257e76435e869703b0ee69d91d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8e814cf7c94ca986665aef4d7e7208": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1f15797fcc34af989a23366ddb11496",
            "placeholder": "​",
            "style": "IPY_MODEL_3eeb0ff03d8a40c7848e9145e74a42df",
            "value": " 6/6 [00:00&lt;00:00, 78.32it/s]"
          }
        },
        "c5137ef4ac99473e88c48121f4283e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9ecded571b0424681218b20cc3ccbdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca14aae9a48e4b31897c63718b6fd192": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca2c0638a0d042edbf5a63f09bbaf584": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b2b4c702ac44cb1a99409c3ddfb9b02",
            "max": 4976698672,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d46e0f5a461405291212211b9140d79",
            "value": 4976698672
          }
        },
        "cb2fa8b943e8448b9022ed7cd616c65b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb800f5f8a394636a2f75bec4fdd8bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd130aaab5244a3eacabe96de3bf89d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd2b8c7687ab4362bc87d03522e630a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_290da9a273b04abeb0cdc31ebdcf303c",
            "placeholder": "​",
            "style": "IPY_MODEL_ab6c935271ad4cbfb8e10d249273a34c",
            "value": "Fetching 4 files: 100%"
          }
        },
        "cd9f24a759184bbc9a3b67894e89a8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a86c30abbf448ebb45171bcfa002e41",
            "max": 4999802720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebc8fb0f47a8408d9abc1cf62abc7161",
            "value": 4999802720
          }
        },
        "cddf9b4df5c54841885f9cfbcc696610": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d310e606ec584b5ab5b34f68a40bde2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d59e586c3ad54887bae3613aada80d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84d2443e7fa1407783679f53530e5fd8",
            "placeholder": "​",
            "style": "IPY_MODEL_16ee78b5a5424fb7bdd7466b89202cf8",
            "value": "config.json: 100%"
          }
        },
        "da257d696c7b4df4aec14ce453cab0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e196f66208d4bcc82d76d688440e9aa",
            "placeholder": "​",
            "style": "IPY_MODEL_8438d56f033e45cd97e0430f6eb1d832",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "da8117e5d87b4312a5dcd43605794259": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db12b15823da4a3a8ef8924b93e251da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc6a945ab0f646eb8df0c07d2eda29f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8352186e7fd943608ef4f99886c9440b",
              "IPY_MODEL_00a0d988d0de498e8c1b3ff5109a6eeb",
              "IPY_MODEL_2c27902bc000443b818139f70eb61e3c"
            ],
            "layout": "IPY_MODEL_31282d7b60834a5eb8e110c521afaf6c"
          }
        },
        "defd5eb9abd848f5b23e0551b5a9f5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4a3fb269b8a4c2b89d8b66a49355cf9",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_511662e2328a4db6a7113ef1ce153616",
            "value": 6
          }
        },
        "e170a06a5e1f47cc919475dbf9acbbf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f46b4c7b5f46a8bf74a74d54fbd672": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4957eda81a764c8c8db97faa508eae07",
            "max": 1168138808,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a2177b8c55346bcba826e750a6b9397",
            "value": 1168138808
          }
        },
        "e8b3d3f8f1394d239c16ac6ffedc80cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e95fcc6887d84a2187a9adf49510d3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebc8fb0f47a8408d9abc1cf62abc7161": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ece248ac57da41a0bce7422ce650c954": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0e487f3226b4cf9a7b551168704be0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f539c621d00b4394a2c626cafb0b0af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6406d0a73eb48a7b4f8b223c38413b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8adb68abc34448e9296a7ac6b77df23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8f345ea9fe14f36a0eeff569d8a3a68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f985c31c354c499488d99d707ce0b8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afad3a65be574363be3ace3c601fe6cf",
            "placeholder": "​",
            "style": "IPY_MODEL_c5137ef4ac99473e88c48121f4283e64",
            "value": "generation_config.json: 100%"
          }
        },
        "fada3792c405449c90cfe70a39d5100a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe5282a2b7e34f189d8dcb370a6eaa1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff172d6123024cf7be5ecf7e9c126c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_601e34a60adc48199f4f1f5b95eb8e95",
            "placeholder": "​",
            "style": "IPY_MODEL_4c50c71c536c4a2185757e5e0fefc7b1",
            "value": "model-00003-of-00004.safetensors: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
